{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Defining an **adopted user** as a user who has logged into the product on three separate days in at least one sevenday period, identify which factors predict future user adoption.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# loading the data #\n",
    "user = r\"data\\takehome_users.csv\"\n",
    "eng = r\"data\\takehome_user_engagement.csv\"\n",
    "\n",
    "df_user = pd.read_csv(user, encoding=\"ISO-8859-1\")\n",
    "df_eng = pd.read_csv(eng, parse_dates=[\"time_stamp\"])\n",
    "\n",
    "df_user = df_user.rename({\"object_id\":\"user_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining an 'adopted user' #\n",
    "df_agg = df_eng.set_index(\"time_stamp\")\n",
    "\n",
    "users = df_agg[\"user_id\"].unique()\n",
    "adoption = []\n",
    "\n",
    "for i in users:\n",
    "    id_filter = df_agg[\"user_id\"] == i\n",
    "    df_filter = df_agg[id_filter].resample(\"1D\").count()\n",
    "    df_filter = df_filter.rolling(window=7).sum()\n",
    "    df_filter = df_filter.dropna()\n",
    "    adoption.append(any(df_filter[\"visited\"].values >= 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 'adopted_user' logic onto df #\n",
    "user_adoption = list(zip(users, adoption))\n",
    "\n",
    "df_adopt = pd.DataFrame(user_adoption)\n",
    "df_adopt.columns = [\"user_id\", \"adopted_user\"]\n",
    "\n",
    "df = df_user.merge(df_adopt, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping 'adopted_user' #\n",
    "df.loc[:, \"adopted_user\"] = df[\"adopted_user\"].map({False:0, True:1, np.nan:0})\n",
    "df.dropna(subset=[\"adopted_user\"], inplace=True)\n",
    "df[\"adopted_user\"] = df[\"adopted_user\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping 'invited_by_user' #\n",
    "invite = lambda row: 0 if np.isnan(row) else 1\n",
    "df[\"invited_by_user\"] = df[\"invited_by_user_id\"].apply(invite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final df #\n",
    "df = df[[\"adopted_user\", \"invited_by_user\", \"creation_source\", \\\n",
    "         \"opted_in_to_mailing_list\", \"enabled_for_marketing_drip\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'rf__max_depth': 5, 'rf__n_estimators': 50}\n",
      "Training accuracy score from tuned model:        94.8%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# machine learning pipeline #\n",
    "X = df[df.columns[1:]]\n",
    "y = df[df.columns[0]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.6, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"encoder\", OneHotEncoder()), \\\n",
    "                           (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "params = {\"rf__n_estimators\" : [50, 75, 100],\n",
    "          \"rf__max_depth\" : [5, 10, 15]}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=params, cv=3)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {cv.best_params_}\")\n",
    "print(f\"Training accuracy score from tuned model: \\\n",
    "       {cv.best_score_*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 94.82%\n"
     ]
    }
   ],
   "source": [
    "# test set score #\n",
    "y_pred = cv.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: 0.127 | Feature: creation_source_PERSONAL_PROJECTS\n",
      "Weight: 0.110 | Feature: creation_source_GUEST_INVITE\n",
      "Weight: 0.084 | Feature: enabled_for_marketing_drip\n",
      "Weight: 0.074 | Feature: creation_source_ORG_INVITE\n",
      "Weight: 0.055 | Feature: invited_by_user\n",
      "Weight: 0.031 | Feature: creation_source_SIGNUP\n",
      "Weight: 0.005 | Feature: creation_source_SIGNUP_GOOGLE_AUTH\n",
      "Weight: 0.000 | Feature: opted_in_to_mailing_list\n"
     ]
    }
   ],
   "source": [
    "# replicating the pipeline without #\n",
    "# using the pipeline itself to get #\n",
    "# \"labeled\" feature importance     #\n",
    "\n",
    "X_ohe = pd.get_dummies(X_test)\n",
    "pipeline.fit(X_ohe, y_test)\n",
    "\n",
    "fe = pipeline.named_steps[\"rf\"].feature_importances_\n",
    "\n",
    "feature_importance = zip(X_ohe.columns, fe)\n",
    "feature_importance = sorted(feature_importance, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "for i, j in feature_importance:\n",
    "    print(f\"Weight: {j:.3f} | Feature: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer ###\n",
    "From the raw dataset, we've utilized the following as our features:\n",
    " 1. **invited_by_user** - if a user was *referred* by another user (custom feature)\n",
    " 2. **creation_source** - how the account was created (stock feature)\n",
    " 3. **opted_in_to_mailing_list** - whether user has opted into receiving marketing emails (stock feature)\n",
    " 4. **enabled_for_marketing_drip** - whether they are on the regular marketing email drip (stock feature)\n",
    " \n",
    "Our model proved itself well having a final accuracy metric comparable to the cross-validation training score (both at ~94%). Which would mean that our pipeline's *feature ranking* is likewise reliable in determining what a good predictor for user adoption is. Thanks to *one-hot encoding* we can clearly see quite specifically what the business could do to potentially boost the likelihood user engagement:\n",
    "1. Because **personal workspace** and **guest invite** rank highest on how users signed up and caught on, the business could realign its marketing goals to focus more on highly-collaborative user groups.\n",
    "2. The **marketing drip** scheme works and so it's important to retain this effort in keeping the user base intact.\n",
    "3. Whether a user opts in the **mailing list** or not shows to be the least effective predictor and so it doesn't quite matter when there is any emphasis on the newsletter call-to-action. At least it'll help the UI team to keep the app less *commercial* and enable a good vibe for the user."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
